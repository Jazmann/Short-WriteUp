%*****************************************************************************************
%*********************************** Second Chapter **************************************
%*****************************************************************************************


\chapter{Color Spaces and Information Storage for Computer Vision Processing} \label{sec:Chap2}

\epstopdfsetup{outdir=Chapter2/Figs/PDF/}
\ifpdf
    \graphicspath{{Chapter2/Figs/Raster/}{Chapter2/Figs/PDF/}{Chapter2/Figs/}}
\else
    \graphicspath{{Chapter2/Figs/Vector/}{Chapter2/Figs/}}
\fi


\section{Constructing a New Color Space}\label{sec:ConstructingANewColorSpace}

In order to construct a new color-space, we need to consider the coordinate system, the orientation, and the fidelity of the discrete representation of the axes.

A Cartesian coordinate system allows for a straightforward transformation from the RGB source involving only rotation, translation and scaling. An orientation with a luminosity axis is useful because we're interested in the color information in the image. This choice determines two of three rotational degrees of freedom, as will be discussed below.

As for the discrete representation of the axes, it's desired that all the information captured pertaining to skin color should be preserved.

\subsection{Camera RGB and Normalization for Discrete Range}\label{sec:CameraRGB}

Due to the iPhone hardware being locked down at the application level, we do not have access to the raw camera feed. We do, however, have access to the post-processing (color-rebalanced and white-point-corrected) 8-bit RGB image data. Investigating the difficulties introduced by these processing effects and accounting for them is looked at in Chapter  \ref{sec:iPhoneCameraCharacteristics}.

Computer vision tasks are computationally intensive and often operate in real time. Reduction of the image data set size is a simple method for improving performance. There is, therefore, a need to develop techniques which keep the relevant information while quickly and efficiently discarding the irrelevant information. Achieving this for the RGB space is the aim of this chapter.

\section{The Skin Color Space Algorithm}

Appendix A outlines how an integer rotation matrix can be found and Appendix B describes how the rotated pixel values can be redistributed preserving all the chromatic information in a particular region. We can use these methods to build a color-space transformation algorithm which can make intelligent decisions about the numerical precision for the intermediate and final variables, as well as determining the most efficient transformation methods. The algorithm described herein will take values of $\theta$, the rotation about the luminosity axis, the standard deviations $ \uSTD{a}$,$ \uSTD{b}$ and mean values $ \uMean{a}$,$ \uMean{b}$ for the two chromatic axes in the unit range  and will automatically decide upon the necessary intermediate working data types and the most efficient re-distribution methods.

We found a rotational transformation which allows a working type $\tRange$ to be chosen such that $\tRange \le 2 \srcRange$ (Appendices \ref{app:AnIntegerRotationMatrix} and \ref{app:PreservationOfColorInformation}, where $\srcRange$ is the source type. If we were to keep the same data type $\dstRange$ for the color-space destination type as is used for the RGB values' source type $\srcRange$, then the axes would have to be rescaled with the accompanying loss of information. Given that we have values which allow us to assess where all the relevant information lies, a more sophisticated approach is possible. For a chromatic axis --- which, after rotation, has a length $L(\theta)$ --- we can determine the positions on that axis at which the information is considered irrelevant using Equation~(\ref{eq:LowHigh}) and the positions where the information is all considered relevant. If the gradient $ \Delta$ (\ref{eq:gradient}) is less than 1, then the distribution loses information at all points on the axis and the axis can be shortened without loss of relevant information. The only further consideration is to ensure that the values outside that range are prevented from causing errors associated with overflow. To exclude this possibility, a conditional statement can be used which checks the bounds as stated, assigning an appropriate value as necessary. The alternative is to use an intermediate value with a higher bit depth, and then to recast into the destination data type in such a way that overflow and underflow are handled appropriately. The OpenCV library provides a casting method --- "saturateCast" --- which serves this purpose.

\subsection{Setting the Value for the Tolerance}
Now that we have the working type range $\tRange$, accounting for both the rotation and the statistics, we can set a meaningful tolerance on the error. Previously, we calculated that the maximum error would occur for pixel values at the corners of the RGB cube; we have now seen that some values are more important than others and that it is more meaningful to use a smaller RGB cube which encloses only the values of interest. This cube is found by taking the values for $\Discard$ as the corners in the rotated space and rotating back to the RGB space. As this only needs to be done once it can be performed using floats in the unit spaces, however the values of $\discard$ account for the discrete numerics in that they are calculated from the discrete values $\Discard$ using the new values for $\kappa$ and $\tRange$ (Equations \ref{eq:DistributionConstants} and \ref{eq:newCompressionRatio}), where $\kappa$ is the compression ratio . In order to perform the inverse rotation, the values must be shifted to compensate for the natural range of the rotation which is: $\{0:1,-\text{\textonehalf}:\text{\textonehalf},-\text{\textonehalf}:\text{\textonehalf}\}$. 

\begin{align}
\discard^{RGB}_2 &= \nR^{-1} \cdot \left( \discard_2 - \Rc
        \right) & \text{where} \quad \Rc=\begin{pmatrix}
                 0   \\
                 \frac{1}{2}    \\
                 \frac{1}{2}     \\
                \end{pmatrix} \\
&= \R^{T} \cdot \left( \nS \otimes \left( \discard_2 - \Rc
                \right) \right)  
\end{align}

Because rotations of any angle are allowed, the values for $\discard^{RGB}_1$ may be larger than those for $\discard^{RGB}_2$ in the RGB space. The values may also be outside the RGB cube, meaning that the values may have to be truncated to fit inside the RGB cube range. 

The perturbation to the rotated channel elements $\dW$ (Equation \ref{eq:thePerturbationToTheRotatedChannelElements}) is found for an input set of pixel values $\discard^{RGB}_2$

\begin{align*}
\dW    &=  \min\left\{K \delta(\mu,\sigma) \right. ,  \left. \mathbf{L}(\theta) \right\} 
 \otimes 
        \begin{pmatrix}  0   \\   2   \\  2    \\ \end{pmatrix} 
  \otimes
        \dqEO\left[   \begin{pmatrix}  0   \\ \dqRe[ \thetaA ]  \\ \dqRe[ \Pii{6} -\thetaA]   \\ \end{pmatrix}  \right]
 \otimes
        \left( \dqs[\theta]  \cdot \discard^{RGB}_2 \right) 
\end{align*}

We have previously solved the case where both channels are of equal importance; we now need to find the values of $\alpha$ and $\beta$ which set the relative importance of each channel. There are two factors here: the channel scaling and the new, smaller RGB cube corners. The values for these also need to be put in correct correspondence with the $a$ and $b$ channel functions. For the scaling this is found by:

\begin{align*}
 \begin{pmatrix}  0   \\   \alpha_1   \\  \beta_1   \\ \end{pmatrix}     &=  
\dqEO\left[  \min\left\{K \delta(\mu,\sigma) \right. ,  \left. \mathbf{L}(\theta) \right\} 
 \otimes 
        \begin{pmatrix}  0   \\   2   \\  2    \\ \end{pmatrix} \right]
\end{align*}
For the new RGB corners we need to find the largest element which can result from the inner product with $\dqs[\theta]$. As the elements of $\dqs[\theta]$ are in $\{-1,0,1\}$, with only one occurrence of each in the second and third rows, we need to find the largest element of $\discard^{RGB}_2$ which is not in the zero position. The algorithm solves:

\begin{align*}
 \begin{pmatrix}  0   \\   \alpha_2   \\  \beta_2   \\ \end{pmatrix}     &=  
\dqEO\left[  
\max \left\{\text{abs}(\dqs[\theta]) \otimes \left(\discard^{RGB}_2 \right)^T \right\}
\right]
\end{align*}
where $\text{max}$ acts on each row and $\text{abs}(\dqs[\theta])  = \dqs[\theta] \otimes \dqs[\theta]$. 
These then give a combined value for $\alpha = \alpha_1 \alpha_2$ and $\beta = \beta_1 \beta_2$. Because the axes have been scaled so that the information on the axis is to be kept, at least, near the mean, the tolerance should be set to $\tau =1$. The condition for accepting a value of $\theta$ is $1 > h(i,\iota; \alpha,\beta)$.

\subsection{The Complete Algorithm}


The programmer specifies a requested value of $\theta$, values for the means $\uMean{{ab}}$ and standard deviations $\uSTD{ {ab}}$ for each of the three axes in the rotated color-space with a unit range and the data type ranges $\srcRange$ and $\dstRange$. The algorithm then proceeds as follows:
\newline
\algosection{Find the working type and range.} 
Using the distribution constants (\ref{eq:DistributionConstants}), the gradient at the mean in the unit range (\ref{eq:gradient}), and the natural rotated axis lengths (\ref{eq:L}):

%\begin{tabular}{|c|c|c|c|}
%\hline  \LaTeX & Mathematica & MatLab & C++ \\ 
%\hline  &  &  &  \\ 
%\hline  &  &  &  \\ 
%\hline  &  &  &  \\ 
%\hline  &  &  &  \\ 
%\hline  &  &  &  \\ 
%\hline  &  &  &  \\ 
%\hline  &  &  &  \\ 
%\hline  &  &  &  \\ 
%\hline 
%\end{tabular} 

\begin{gather*}
 \begin{aligned}
  \delta  &= \frac{ \sqrt{2} }{ \sigma \sqrt{\pi }  \left(\Sigma^+-\Sigma^-\right)} & 
 K & =  \frac{\dstRange}{\srcRange}  & 
 \Sigma^- &= \text{erf}\left(\frac{\mu -1}{\sqrt{2} \sigma }\right) &
 \Sigma^+ &= \text{erf}\left(\frac{\mu }{\sqrt{2} \sigma }\right) 
  \end{aligned} \\
  \mathbf{L}(\theta) =
  \begin{pmatrix}
  \sqrt{3} \\
   \sqrt{\frac{2}{3}} \sin \left(\widetilde{\vartheta}\right) + \sqrt{2} \cos \left(\widetilde{\vartheta}\right) \\  
  \sqrt{\frac{2}{3}} \sin \left(\widetilde{\theta}\right) + \sqrt{2} \cos \left(\widetilde{\theta}\right) 
  \end{pmatrix}
  \quad \text{where}  \quad 
  \begin{array}{c}
  \widetilde{\vartheta} = \left(\theta - \Pii{6}\right) \bmod \frac{\pi }{3} \\
  \widetilde{\theta} = \theta  \bmod \frac{\pi }{3} 
  \end{array}
\end{gather*}
The length of the axis $\tRange$ after rescaling is given by Equation \ref{eq:CombinedRotationRange}, and the axis limits are easily found along with 
the compression ratio $\kappa$ (Equation \ref{eq:newCompressionRatio}).
\begin{gather*}
\begin{aligned}
 \tRange(\theta,\mu,\sigma)   & =  \min\left\{K \delta(\mu,\sigma) \right. ,  \left. \mathbf{L}(\theta) \right\}  \srcRange \quad&\quad
 \kappa(\theta) & = \max\left\{ \frac{1}{\delta(\mu,\sigma) }   , \frac{K}{\mathbf{L}(\theta)} \right\}  
 \end{aligned} \\
 \begin{aligned}
  \tMin(\theta,\mu,\sigma)   & =
 \begin{pmatrix}
 0 \\
  \frac{-1 }{2} \tRange_2(\theta,\mu_2,\sigma_2) \\  
  \frac{-1 }{2} \tRange_3(\theta,\mu_3,\sigma_3) \\  
 \end{pmatrix} \quad & \quad
  \tMax(\theta,\mu,\sigma)   & =
 \begin{pmatrix}
  \tRange_1(\theta,\mu_1,\sigma_1)  \\
  \frac{1 }{2} \tRange_2(\theta,\mu_2,\sigma_2)  \\  
  \frac{1 }{2} \tRange_3(\theta,\mu_3,\sigma_3)  \\  
 \end{pmatrix} 
 \end{aligned}
\end{gather*}


\algosection{Set the distribution region boundary constants.} 
Using the constants defined in Equations \ref{eq:PreservedRegionConsts} and \ref{eq:0to1}
\begin{align*}
  w(\mu,\sigma)  & =  \sigma  \sqrt{ \log \left(\frac{2}{\pi } \right) -2 \log \left(\kappa \sigma  \left(\Sigma^+-\Sigma^-\right)\right) } &
  \text{dL} &= \frac{1}{\dstRange} 
\end{align*}
We find the boundaries in the unit range 
\begin{equation}
\begin{aligned}
\discard_1 &= \sigma \sqrt{2} \; \text{erf}^{-1}\left((\text{dL}-1) \Sigma^+-\text{dL} \; \Sigma^-\right)+\mu  &       
\keep_1(\mu,\sigma) &= \mu - w(\mu,\sigma)  \\     
\discard_2 &= \sigma \sqrt{2} \; \text{erf}^{-1}\left((\text{dL}-1) \Sigma^- -\text{dL} \; \Sigma^+ \right)+\mu &
\keep_2(\mu,\sigma) &= \mu + w(\mu,\sigma) 
\end{aligned}
\end{equation}
and the boundaries in the working range
\begin{equation}
\begin{aligned}
\Discard &= \tMin + \tRange \left( \discard(\mu,\sigma) \right) & 
\Keep(\mu,\sigma) &= \tMin + \tRange\left( \keep(\mu,\sigma) \right) 
\end{aligned}
\end{equation}
The extended region in which all the information is kept is found by numerically solving the defining equations for the  extended boundaries $\eKeep_1$ and $\eKeep_2$ with the practical introduction of a parameter $ \tau_{p} $, which extends the acceptable deviation from linearity. So $ \tau_{p} =1$ would allow 1 discarded piece of information within the extended region.
\begin{equation}
\begin{aligned}
\left\lceil\text{dis}\left(\Keep _1\right)\right\rceil-\Keep _1 - \tau_{p} & =\text{dis}\left(\eKeep _1\right)- \eKeep _1 &
\left\lfloor\text{dis}\left(\Keep _2\right)\right\rfloor-\Keep _2 - \tau_{p} & =\text{dis}\left(\eKeep _2\right)- \eKeep _2 
\end{aligned}
\end{equation}
The C++ code finds the points using the following algorithm

\begin{algorithm}[H]
\begin{algorithmic}
 \Require{$\Keep _2$ the starting point for the linear walk } 
 \linebreak \phantom{Require} $\tau_{p}$ the acceptable divergence from linearity 
 \Ensure{$ \{\eKeep_1, \eKeep_2\} $ the extended boundaries}
 \State $x \gets \Keep_2$  \Comment{$dis(x)$ is the distribution function}
 \While{$dis(x) > x + \left\lfloor\text{dis}\left(\Keep _2\right)\right\rfloor  -\Keep _2 - \tau_{p}$}
     \State  x++ 
 \EndWhile
 \State $\eKeep_2 \gets x$ 
 \State $\eKeep_1 \gets \Keep _1 - (\eKeep_2 - \Keep _2)$ \Comment{Exploiting a symetry dis(x)}
 \State \textbf{Return} {$\eKeep_1$ ,$\eKeep_2$ }
 \end{algorithmic}
  \caption{Finding the extended region in which all the information is kept in C++}
\end{algorithm}

The unit range boundaries $\ekeep$ are found using  $\ekeep =  \frac{\eKeep - \tMin}{\tRange}$.


\algosection{Suggest a new value for $\theta$.} 
First we find the perturbation scaling (\ref{eq:perturbationFunctionSigns}) and the perturbation function ordering function (\ref{eq:abPerturbationFunctionOrdering}).
%\begin{gather}\label{eq:abPerturbationFunctionOrdering}
%\dqEO[  \left(
%\begin{smallmatrix}
% 0   \\
% a   \\
% b  \\
% \end{smallmatrix} 
%\right)  ,\theta ] =
%\begin{cases}
% \left(
%\begin{smallmatrix}
% 0 \\
% a  \\
% b \\
%\end{smallmatrix} 
%\right) & 0\leq (\theta  \bmod \frac{\pi}{3} )<\frac{\pi }{6} \\
% \left(
%\begin{smallmatrix}
% 0 \\
% b  \\
% a \\
%\end{smallmatrix} 
%\right) & \frac{\pi }{6} \leq (\theta  \bmod \frac{\pi}{3} ) < \frac{\pi }{3} 
%\end{cases} \\
%\dqs[\theta] =
%\begin{cases}
% \left(
%\begin{smallmatrix}
% 0 & 0 & 0 \\
% 1 & 0 & -1 \\
% 1 & -1 & 0 \\
%\end{smallmatrix} 
%\right) & 0\leq (\theta  \bmod \pi )<\frac{\pi }{6} \\
% \left(
%\begin{smallmatrix}
% 0 & 0 & 0 \\
% 0 & 1 & -1 \\
% -1 & 1 & 0 \\
%\end{smallmatrix} 
%\right) & \frac{\pi }{6}\leq (\theta  \bmod \pi )<\frac{\pi }{3} \\
% \left(
%\begin{smallmatrix}
% 0 & 0 & 0 \\
% 0 & -1 & 1 \\
% -1 & 0 & 1 \\
%\end{smallmatrix} 
%\right) & \frac{\pi }{3}\leq (\theta  \bmod \pi )<\frac{\pi }{2} \\
% \left(
%\begin{smallmatrix}
% 0 & 0 & 0 \\
% 1 & -1 & 0 \\
% 1 & 0 & -1 \\
%\end{smallmatrix} 
%\right) & \frac{\pi }{2}\leq (\theta  \bmod \pi )<\frac{2 \pi }{3} \\
% \left(
%\begin{smallmatrix}
% 0 & 0 & 0 \\
% -1 & 1 & 0 \\
% 0 & 1 & -1 \\
%\end{smallmatrix} 
%\right) & \frac{2 \pi }{3}\leq (\theta  \bmod \pi )<\frac{5 \pi }{6} \\
% \left(
%\begin{smallmatrix}
% 0 & 0 & 0 \\
% -1 & 0 & 1 \\
% 0 & -1 & 1 \\
%\end{smallmatrix} 
%\right) & \frac{5 \pi }{6}\leq (\theta  \bmod \pi )<\pi 
%\end{cases}
%\end{gather}
In order to set the values for the scaling of the perturbation $\alpha$ and $\beta$, the absolute value of the perturbation matrix sign $\left\lVert \dqs[\theta] \right\rVert$ can be written in terms of a single row vector function $\dqas[\theta]$ 
\begin{align*}
\left\lVert \dqs[\theta] \right\rVert & = 
\left( \begin{smallmatrix}  0&0&0   \\   \cdots & \dqas[\theta + \frac{\pi}{2}] & \cdots   \\  \cdots & \dqas[\theta]   & \cdots  \\ \end{smallmatrix}  \right) 
&
\dqas[\theta] &=\begin{cases}
\left(\begin{smallmatrix} 1 & 1 & 0 \end{smallmatrix} \right)&  0                     \leq \scalebox{0.75}{ $(\theta \bmod \pi )$ }<\frac{   \pi }{3} \\
\left(\begin{smallmatrix} 1 & 0 & 1 \end{smallmatrix} \right)&  \frac{   \pi }{3}\leq \scalebox{0.75}{ $(\theta \bmod \pi )$ }<\frac{2 \pi }{3} \\
\left(\begin{smallmatrix} 0 & 1 & 1 \end{smallmatrix} \right) & \frac{2 \pi }{3}\leq \scalebox{0.75}{ $(\theta \bmod \pi )$ }<\pi  \\
\end{cases} 
\end{align*}
Then we find the point at which loss of information does not matter in RGB space $\discard^{RGB}_2$ 
\begin{align*}
\discard^{RGB}_2 &= \max \left\{ 
  \R^{T} \cdot \left( \nS \otimes \left( \discard_1 - \Rc \right) \right) , 
  \R^{T} \cdot \left( \nS \otimes \left( \discard_2 - \Rc \right) \right) 
\right\} &
 \text{where} \quad \Rc=
\begin{pmatrix}
                 0   \\
                 \frac{1}{2}    \\
                 \frac{1}{2}     \\
\end{pmatrix} 
\end{align*}

Then we numerically find 

\begin{align*}
 \begin{pmatrix}  0   \\   \alpha   \\  \beta   \\ \end{pmatrix}     % &=  
%\dqEO\left[  \min\left\{K \delta(\mu,\sigma) \right. ,  \left. \mathbf{L}(\theta) \right\} 
% \otimes 
%        \begin{pmatrix}  0   \\   2   \\  2    \\ \end{pmatrix} 
%         \otimes 
%        \max \left\{\text{abs}(\dqs[\theta]) \otimes \left(\discard^{RGB}_2 \right)^T \right\}
%        \right]\\
        &=\dqEO\left[ \begin{pmatrix} 
         0 \\ 
         2 \min\left\{K \delta(\mu_2,\sigma_2) \right. ,  \left. \mathbf{L}_2(\theta) \right\}  \max \left\{\dqas[\theta + \frac{\pi}{2}]  \otimes \left(\discard^{RGB}_2 \right)^T \right\}  \\
         2 \min\left\{K \delta(\mu_3,\sigma_3) \right. ,  \left. \mathbf{L}_3(\theta) \right\}  \max \left\{\dqas[\theta                       ] \otimes \left(\discard^{RGB}_2 \right)^T \right\}   \\
          \end{pmatrix} \right]
\end{align*}

The algorithm then finds a starting value for the index (\ref{eq:indexFromTheta}) and returns the closest value which satisfies the tolerance (\ref{eq:generalizedPerturbation}):

%\setlength{\belowdisplayskip}{0pt} \setlength{\belowdisplayshortskip}{0pt}
%\setlength{\abovedisplayskip}{0pt} \setlength{\abovedisplayshortskip}{0pt}

\begin{align*}
 i(\delta\theta, n) &= \frac{\meanIndx \tan (\delta \theta ) \left(\sqrt{3} \tan (\delta \theta )+7\right)}{\tan (\delta \theta )+\sqrt{3}} &
  \delta\theta &= \theta \mod{\frac{\pi}{6} } &
  \meanIndx & = 2^{n-3} 
\end{align*}

The region $\iota$ for a given value of $i$ is found and the appropriate values (\ref{eq:extremaBounds}) for the extrema (\ref{eq:ExtremaFunctions}) are evaluated in the function which finds the perturbation at the index (\ref{eq:generalizedPerturbation}) and the intercept position $\thetaX{i}$ is found with algorithm \ref{algo:thetaX}.
%\begin{gather*}
%\begin{aligned}
% \iota(i,n)  &= \left\lfloor 7\ \meanIndx-\sqrt{i^2 - 2 i \; \meanIndx + 49\ \meanIndx^2 }\right\rfloor &
%  \extremaTheta{a} {l} = & \arctan\left(\frac{l \sqrt{3} }{2^n - l}\right) &
%  \extremaTheta{b} {l} = & \arctan\left(\frac{l \; 2^{2-n}}{\sqrt{3}}       \right)
%\end{aligned} \\
%\begin{aligned}
% \minimaTheta{a}  &= \extremaTheta{a}{i+\iota} &
% \maximaTheta{b} &= \extremaTheta{b}{i-\iota-1} & 
% \minimaTheta{b}  &= \extremaTheta{b}{i-\iota}  &
% \maximaTheta{a} &= \extremaTheta{a}{i+\iota+1}  &
%  \text{when} \quad 
%i + \iota &\in \{2 \mathbb{N}     \} \\
% \maximaTheta{a}  &= \extremaTheta{a}{i+\iota} & 
% \minimaTheta{b}  &= \extremaTheta{b} {i-\iota-1} &
% \maximaTheta{b} &= \extremaTheta{b}{i-\iota}  &
% \minimaTheta{a}  &= \extremaTheta{a}{i+\iota+1}  & 
%\text{when} \quad 
%i + \iota &\in \{2 \mathbb{N}  + 1 \} 
%\end{aligned}\\
%\thetaX{i} = \left\{\frac{
%\beta \minimaTheta{b} (\minimaTheta{a}  -\maximaTheta{a} )+\alpha  \minimaTheta{a} (\maximaTheta{b}-\minimaTheta{b})  }{
%\beta  (\minimaTheta{a} -\maximaTheta{a})+\alpha  (\maximaTheta{b}-\minimaTheta{b})
%},\frac{
%\alpha  \beta  (\minimaTheta{a}-\minimaTheta{b})  }{
%\beta  (\minimaTheta{a}-\maximaTheta{a})+\alpha  (\maximaTheta{b}-\minimaTheta{b})
%}\right\}
%\end{gather*}

 \begin{algorithm}[h]
 \begin{algorithmic}
      \Function { $\overset{\times}{\phi}$}{$ i, \alpha, \beta, n $} \Comment{$i$ integer index of the intercept }
       \State $\meanIndx \gets  2^{n-3}$  ; \quad  $\iota(i,n)  \gets  \left\lfloor 7\ \meanIndx-\sqrt{i^2 - 2 i \meanIndx + 49\ \meanIndx^2 }\right\rfloor $  \Comment{$n$ the source bit depth}
        \State $\extremaTheta{b}{\mathbf{l} } = \arctan\left(\frac{\mathbf{l} 2^{2-n}}{\sqrt{3}}       \right)$ ; \quad 
        $\extremaTheta{a}{\mathbf{l} } = \arctan\left(\frac{\mathbf{l} \sqrt{3} }{2^n - \mathbf{l}}\right)$
        \If{$ i + \iota \bmod{2} = 0$}  \Comment{$i + \iota$ is even}
               \State   $\maximaTheta{a} \gets \extremaTheta{a}{i+\iota+1}  $ ;\quad
                 $\minimaTheta{a}  \gets \extremaTheta{a}{i+\iota} $ 
               \State   $\maximaTheta{b} \gets \extremaTheta{b}{i-\iota-1} $ ;\quad
                 $\minimaTheta{b}  \gets \extremaTheta{b}{i-\iota}  $
         \Else
                \State  $\maximaTheta{a}  \gets \extremaTheta{a}{i+\iota} $ ;\quad
                 $\minimaTheta{a}  \gets \extremaTheta{a}{i+\iota+1}  $ \;
                \State  $\maximaTheta{b} \gets \extremaTheta{b}{i-\iota}  $ ;\quad
                 $\minimaTheta{b}  \gets \extremaTheta{b} {i-\iota-1} $ \;
         \EndIf
       \State  $\thetaX{i} \gets \left\{\frac{
        \beta \minimaTheta{b} (\minimaTheta{a}  -\maximaTheta{a} )+\alpha  \minimaTheta{a} (\maximaTheta{b}-\minimaTheta{b})  }{
        \beta  (\minimaTheta{a} -\maximaTheta{a})+\alpha  (\maximaTheta{b}-\minimaTheta{b})
        },\frac{
        \alpha  \beta  (\minimaTheta{a}-\minimaTheta{b})  }{
        \beta  (\minimaTheta{a}-\maximaTheta{a})+\alpha  (\maximaTheta{b}-\minimaTheta{b})
        }\right\} $ \;
      \State \textbf{Return} {$\thetaX{i}$}\Comment{$\thetaX{i} $ \{angle,  maximum perturbation\} }
\EndFunction
 \end{algorithmic}
    \caption{A function which returns the angular position of compromise between the perturbations to the channels.}
    \label{algo:thetaX}
\end{algorithm}
%the angular position of the intercept and the maximum perturbation at that value

To find the angular value closest to $\theta$ which produces a perturbation less than the tolerance $\tau$, algorithm \ref{algo:newTheta} finds the closest value which satisfies the tolerance in the positive and negative directions and returns the nearest one to the requested value of $\theta$. Algorithm \ref{algo:newTheta} is guaranteed to find a value which satisfies the tolerance in each direction within a $\frac{\pi}{6}$ region because the perturbation is zero at the ends of the $\frac{\pi}{6}$ region.
 
\begin{algorithm}[H]
 \begin{algorithmic}
  \Require{ $\alpha$, $\beta$ the relative importance of the channels}
  \State \phantom{Require}  { $\theta$ the requested angle; \quad \quad $\tau$ the tolerance}
 \Ensure{ $\vartheta$ the suggested value for $\theta$ and  $h$ the predicted maximum perturbation.}
 \State  \begin{tabular*}{\textwidth}{c @{\extracolsep{\fill}} lll}
 $\delta\theta \gets \theta \bmod{\frac{\pi}{6} }$; & $\Theta \gets \theta - \delta\theta$;  &  $\meanIndx \gets  2^{n-3} $;
 \end{tabular*}
  \State  \begin{tabular*}{\textwidth}{c @{\extracolsep{\fill}} ll}
  $i_{\circleddash} \gets i_{\oplus} \gets \frac{\meanIndx \tan (\delta \theta ) \left(\sqrt{3} \tan (\delta \theta )+7\right)}{\tan (\delta \theta )+\sqrt{3}} $; & 
  $  \left\{ \vartheta_{\circleddash}, h_{\circleddash} \right\} \gets \left\{ \vartheta_{\oplus}, h_{\oplus} \right\} \gets \thetaX{i, \alpha, \beta, n}$
  \end{tabular*}
 \While{$h_{\oplus} > \tau$}
 \State  $i_{\oplus}++$ \;
 \State  $\left\{ \vartheta_{\oplus}, h_{\oplus}\right\} \gets \thetaX{i_{\oplus}, \alpha, \beta, n}$
 \EndWhile
 \While{$h_{\circleddash} > \tau$}
  \State   $i_{\circleddash}--$ \;
  \State  $\left\{ \vartheta_{\circleddash}, h_{\circleddash}\right\} \gets \thetaX{i_{\circleddash}, \alpha, \beta, n}$
 \EndWhile
  \If{ $\vartheta_{\oplus} -\delta\theta < \delta\theta - \vartheta_{\circleddash}$ }
 \State  $\left\{ \vartheta, h\right\}  = \left\{\Theta + \vartheta_{\oplus}, h_{\oplus}\right\}  $ 
 \Else
  \State $\left\{ \vartheta, h\right\}  = \left\{\Theta + \vartheta_{\circleddash}, h_{\circleddash}\right\} $
  \EndIf
 \State \textbf{Return} {$\left\{ \vartheta, h\right\} $ }
  \end{algorithmic}
    \caption{Suggest a new value for $\theta$}
    \label{algo:newTheta}
 \end{algorithm}
 

\algosection{Set the integer rotation matrix.} 

Expanding the definition of the quantized matrix $\qR[\theta, n]$ (\ref{eq:quantizedMatrixDef}) with the definitions of the factored matrix $\fR[\theta] $ (\ref{eq:factoredMatrixDef}), the matrix ordering $ \fRO \left[ \cdots , \theta \right] $ (Table \ref{tab:factoredRotationMatrix}) and the factored matrix function $\fRe[\phi]$ (\ref{eq:fReDef}) allows a more algorithm minded form to be written.
%
%\begin{align*}
%\fRe[\phi] &= \frac{\um 1}{2} \left(1+\sqrt{3} \tan (\phi )\right)  \\
% \qR[\theta, n] &=
%\round{   \left( \begin{array}{c} 1  \\ 2^{n - 2} \\ 2^{n - 2}  \\ \end{array} \right) \bigotimes \fR[\theta] }
%\quad \text{and} \quad 
%\qS[n] = \left(\begin{array}{c} 1  \\ 2^{2-n } \\ 2^{2-n }  \\ \end{array} \right) \\
% \qR[\theta, n] &=
%\round{   \left( \begin{array}{c} 1  \\ 2^{n - 2} \\ 2^{n - 2}  \\ \end{array} \right) \bigotimes \fRO \left[ \fRm{\thetaA} , \theta \right]  } \\
% \qR[\theta, n] &=
%\round{   \left( \begin{array}{c} 1  \\ 2^{n - 2} \\ 2^{n - 2}  \\ \end{array} \right) \bigotimes 
%\fRO \left[
%\left(\begin{smallmatrix}
% 1 & 1 & 1 \\
% \text{fRe} (\thetaA)  & 1 & -1-\text{fRe} (\thetaA ) \\
% \text{fRe} \left(\frac{\pi }{6}-\thetaA \right) & -1 - \text{fRe} \left(\frac{\pi }{6}-\thetaA \right) & 1 \\
%\end{smallmatrix}\right) , \theta \right] } 
%\end{align*}

%\begin{align*}
%\elemAp & = \fReq{\thetaA } &
%\elemAm & = -1-\fReq{\thetaA }  & 
%\elemBp & = \fReq{\frac{\pi }{6}-\thetaA } & 
%\elemBm & =-1 - \fReq{\frac{\pi }{6}-\thetaA} \\
%\elemAp & = \frac{\um 1}{2} \left(1+\sqrt{3} \tan (\thetaA )\right) &
%\elemAm & = -1-\frac{\um 1}{2} \left(1+\sqrt{3} \tan (\thetaA )\right)  & 
%\elemBp & = \frac{\um 1}{2} \left(1+\sqrt{3} \tan (\frac{\pi }{6}-\thetaA )\right)  & 
%\elemBm & =-1 - \frac{\um 1}{2} \left(1+\sqrt{3} \tan (\frac{\pi }{6}-\thetaA )\right)  \\
%\elemAp & = \frac{\um 1}{2} \left(1+\sqrt{3} \tan (\thetaA )\right) &
%\elemAm & = \frac{\um 1}{2} \left(1-\sqrt{3} \tan (\thetaA )\right)  & 
%\elemBp & = \frac{\um 1}{2} \left(1+\sqrt{3} \tan (\frac{\pi }{6}-\thetaA )\right)  & 
%\elemBm & =\frac{\um 1}{2} \left(1-\sqrt{3} \tan (\frac{\pi }{6}-\thetaA )\right)   \\
%\elemAp  & = -2^{n-3 } \left(1+\sqrt{3} \tan (\thetaA )\right) &
%\elemAm & = -2^{n-3 } \left(1-\sqrt{3} \tan (\thetaA )\right)  & 
%\elemBp  & = -2^{n-3 } \left(1+\sqrt{3} \tan (\frac{\pi }{6}-\thetaA )\right)  & 
%\elemBm & =-2^{n-3 } \left(1-\sqrt{3} \tan (\frac{\pi }{6}-\thetaA )\right)   \\
%\end{align*}

%\begin{tabular}

\begin{gather*}
\begin{aligned}
\qRs &= \fSs \otimes \qR   &   \elemU  &= 2^{n-2 } &
\mTheta{6} &= \theta  \bmod \pi  & \mTheta{1} &= \theta  \bmod \frac{ \pi }{6}\\
\end{aligned} \\
\begin{aligned}
\elemAp  & = - \left(2^{n-3 }+\round{ 2^{n-3 }\sqrt{3} \tan (\thetaA ) }\right) & -2^{n-2} \le & \elemAp \le -2^{n-3} \\
\elemAm & = - \left(2^{n-3 } -\round{ 2^{n-3 }\sqrt{3} \tan (\thetaA )}\right)  & -2^{n-3} \le  & \elemAm \le 0 \\
\elemBp   & = - \left(2^{n-3 } +\round{ 2^{n-3 }\sqrt{3} \tan \left(\frac{\pi }{6}-\thetaA \right) }\right)  & -2^{n-2} \le & \elemBp  \le -2^{n-3} \\
\elemBm  & = - \left(2^{n-3 } -\round{ 2^{n-3 }\sqrt{3} \tan \left(\frac{\pi }{6}-\thetaA \right) }\right)   & -2^{n-3} \le & \elemBm \le 0 \\
\end{aligned} \\
\begin{aligned}
 \qR[\theta, n] % &=
% \round{ \left(\begin{array}{c} 1  \\ 2^{n - 2} \\ 2^{n - 2}  \\\end{array} \right) \bigotimes \fR[\theta] } \\
  &=
\begin{cases}
\left(
\begin{smallmatrix}
 1              & 1             & 1  \\
 \elemAp  & \elemU    & \elemAm \\
 \elemBp   & \elemBm & \elemU \\
\end{smallmatrix}
\right) & 0\leq \mTheta{6}<\frac{\pi }{6} \\
 \left(
\begin{smallmatrix}
 1              & 1             & 1  \\
 \elemU     & \elemBp  & \elemBm \\
 \elemAm  & \elemAp  & \elemU \\
\end{smallmatrix}
\right) & \frac{\pi }{6}\leq \mTheta{6} <\frac{\pi }{3} \\
 \left(
\begin{smallmatrix}
 1              & 1             & 1  \\
 \elemU    & \elemAm & \elemAp \\
 \elemBm  & \elemU   & \elemBp \\
\end{smallmatrix}
\right) & \frac{\pi }{3}\leq \mTheta{6} <\frac{\pi }{2} \\
 \left(
\begin{smallmatrix}
 1              & 1             & 1  \\
 \elemBp   & \elemBm & \elemU \\
 \elemAp   & \elemU   & \elemAm \\
\end{smallmatrix}
\right) & \frac{\pi }{2}\leq \mTheta{6} <\frac{2 \pi }{3} \\
 \left(
\begin{smallmatrix}
 1              & 1             & 1  \\
 \elemAm  & \elemAp & \elemU \\
 \elemU     & \elemBp  & \elemBm \\
\end{smallmatrix}
\right)  & \frac{2 \pi }{3}\leq \mTheta{6} <\frac{5 \pi }{6} \\
\left(
\begin{smallmatrix}
 1              & 1             & 1  \\
 \elemBm  & \elemU   & \elemBp \\
 \elemU    & \elemAm & \elemAp \\
\end{smallmatrix}
\right)  & \frac{5 \pi }{6}\leq \mTheta{6} <\pi 
\end{cases} &
 \fSs[\theta]  &=
\begin{cases}
\left( \begin{smallmatrix}  1 \\    1 \\   1\\ \end{smallmatrix} \right) & 0                   \leq    \mTheta{6}  < \frac{   \pi }{6} \\
\left( \begin{smallmatrix}  1 \\  -1 \\   1\\ \end{smallmatrix} \right) & \frac{  \pi }{6} \leq  \mTheta{6}  < \frac{   \pi }{3} \\
\left( \begin{smallmatrix}  1 \\  -1 \\ -1\\ \end{smallmatrix} \right) & \frac{  \pi }{3} \leq  \mTheta{6}  < \frac{   \pi }{2} \\
\left( \begin{smallmatrix}  1 \\    1 \\ -1\\ \end{smallmatrix} \right) & \frac{  \pi }{2} \leq  \mTheta{6}  < \frac{2 \pi }{3} \\
\left( \begin{smallmatrix}  1 \\    1 \\   1\\ \end{smallmatrix} \right) & \frac{2\pi }{3} \leq  \mTheta{6}  < \frac{5 \pi }{6} \\
\left( \begin{smallmatrix}  1 \\  -1 \\   1\\ \end{smallmatrix} \right) & \frac{5\pi }{6} \leq  \mTheta{6}  <             \pi  \\
\end{cases} 
\end{aligned} \\
\end{gather*}
This $\qRs[\theta, n]$ matrix is used to perform the rotation of the pixel values. Taking the inner product of $\qRs$ with the pixel values produces 
a rotated set of pixel values $\vec{a} = \qRs \cdot \vec{rgb}$ with elements $ \vec{a}_1 \in \{0 \cdots 3 (2^n - 1)\}$,  $ \vec{a}_2 \in 2^{n-2}-2^{2 n-2} \cdots 2^{2 n-2}-2^{n-2}  \}$ and $ \vec{a}_3 \in 2^{n-2}-2^{2 n-2}  \cdots 2^{2 n-2}-2^{n-2}  \}$. 
\begin{align*}
\qRsMin     &= \left( \begin{smallmatrix} 0                \\  2^{n-2}-2^{2 n-2}                  \\ 2^{n-2}-2^{2 n-2}               \\ \end{smallmatrix} \right) & 
\qRsMax    &= \left( \begin{smallmatrix} 3 (2^n - 1) \\  2^{2 n-2}-2^{n-2}                  \\  2^{2 n-2}-2^{n-2}              \\ \end{smallmatrix} \right) & 
\qRsRange &= \left( \begin{smallmatrix} 3 (2^n - 1) \\  2^{n-1} \left(2^n-1\right)      \\  2^{n-1} \left(2^n-1\right)  \\ \end{smallmatrix} \right) 
\end{align*}
\algosection{Design the distribution function.} 
First, the overall scaling for the quantized rotation matrix is found by combining the normalized scaling $\Scale[\theta, n]$ (\ref{eq:scaleDef}) with the desired scaling defined in equation (\ref{eq:CombinedRotationRange}):

\begin{equation*}
\Scale =
 \min\left\{K \delta(\mu,\sigma) \right. ,  \left. \mathbf{L}(\theta) \right\}  \otimes
\begin{pmatrix}
  \frac{1}{3} \\
 2^{1-n } \\
 2^{1-n }  \\
\end{pmatrix}    \\
\end{equation*}

Next, we decide which of the distribution methods should be used. This is done by assessing the size of each of the regions relative to a tolerance. The algorithm avoids unnecessary operations by finding the region directly with the unscaled result of the inner product between the matrix $\qRs$ and the pixel value.
%\begin{align*}
%\mathbf{Q}_{discard}     &\gets \tau_{discard}     \le    1-\discard_2 + \discard_1 \\
%\mathbf{Q}_{distribute} &\gets \tau_{distribute}  \le    \discard_2 - \ekeep_2 + \ekeep_1 - \discard_1 \\
%\mathbf{Q}_{keep}        &\gets  \tau_{keep}         \le     \ekeep_2 - \ekeep_1 
%\end{align*}
%If $\mathbf{Q}_{discard} = \text{True} $ then we find the boundaries in the $0 \cdots 2^{2n}$ range and add the discard function to the distribution function.
%\begin{align*}
%\Discard_1^{q} &= \qRsRange \discard_1 +\qRsMin&
%\eKeep_1^{q} &= \qRsRange \ekeep_1 +\qRsMin \\
%\Discard_2^{q} &= \qRsRange \discard_2 + \qRsMin&
%\eKeep_2^{q} &= \qRsRange \ekeep_2 + \qRsMin&
%\end{align*}
%
% \begin{algorithm}[H]
% \SetKwProg{Fn}{Function}{is}{end}
%      \Fn{discard{t, n}}{
%       \Require{$t$ the channel value  \quad
%        $n$ the source bit depth }
%       \KwResult{$d$ the redistributed channel value}
%       $\Discard_1^{q} \gets \qRsRange \discard_1 + \qRsMin $; \quad 
%       $\Discard_2^{q} \gets \qRsRange \discard_2 + \qRsMin $ \;
%       $\eKeep_1^{q}    \gets \qRsRange \ekeep_1   + \qRsMin $; \quad 
%       $\eKeep_2^{q}    \gets \qRsRange \ekeep_2   + \qRsMin $ \;
%       \SetAlgoLined
%       \uIf{$t < \Discard_1^{q}$}{
%       \textbf{Return} {$\dstMin$ }
%       }
%       \uElseIf{$t > \Discard_2^{q}$}{
%        \textbf{Return} {$\dstMax$ }
%       }
%       \Else{
%              \uIf{$ \eKeep_1^{q} \le t \le \eKeep_2^{q} $}{
%              do linear stuff \;
%              \textbf{Return} {$val$ }
%              }
%	          \Else{
%	              \uIf{$\Discard_1^{q} < t < \eKeep_1^{q}$}{
%	               \textbf{Return} {$val$ }
%	              }
%	               \Else($ \eKeep_2^{q} < t < \Discard_2^{q}$){
%	               \textbf{Return} {$val$ }
%	              }
%              do other distro stuff
%              }
%       }
%       
%      }
% \caption{A function which returns the angular position of compromise between the perturbations to the channels.}
%\end{algorithm}

 \begin{algorithm}[H]
  \begin{algorithmic}
       \Require{$\{\discard, \Discard, \ekeep,\eKeep\}$ the boundaries of the regions.}
       \State \phantom{Require} $0<\tau<1$ the tolerances for counting a region as significant.
       \Ensure{$pDis$ a function which performs the re-distribution for a channel.}
       \State \begin{tabular}{llcrl}
       $\mathbf{Q}_{discard} $    &  $\gets \tau_{discard}     \le    1-\discard_2 + \discard_1$ & \quad\quad&
              $\mathbf{Q}_{keep} $        & $\gets \tau_{keep}         \le     \ekeep_2 - \ekeep_1$\\
       $\mathbf{Q}_{distribute}$ & \multicolumn{4}{l}{$\gets \tau_{distribute}  \le    \discard_2 - \ekeep_2 + \ekeep_1 - \discard_1$} \\
       $\Discard_1^{q}$ &$\gets \qRsRange \; \discard_1 + \qRsMin$; & \quad\quad &
       $\Discard_2^{q}$ &$\gets \qRsRange \; \discard_2 + \qRsMin$ \\
       $\eKeep_1^{q}$    &$\gets \qRsRange \; \ekeep_1   + \qRsMin$; & \quad\quad &
       $\eKeep_2^{q}$    &$\gets \qRsRange \; \ekeep_2   + \qRsMin$ 
       \end{tabular} \;
          \If{$\mathbf{Q}_{keep}  \wedge \mathbf{Q}_{discard} \wedge \mathbf{Q}_{distribute} $}\Comment{Piecewise Erf Distribution}
         \State $
          pDis(x) \gets \begin{cases}
          \dstMin & x \le \Discard_1^q \\
          \text{dis}(\Scale x) & \Discard_1^q < x < \eKeep_1^q \\
          \Scale x - \eKeep_1 + \text{dis}(\eKeep_1) & \eKeep_1^q \le x \le \eKeep_2^q  \\
          \text{dis}(\Scale x) + \eKeep_2 - \eKeep_1 - \text{dis}(\eKeep_2) + \text{dis}(\eKeep_1)  & \eKeep_2^q < x < \Discard_2^q  \\
          \text{dis}(\Discard_2) + \eKeep_2 - \eKeep_1 - \text{dis}(\eKeep_2) + \text{dis}(\eKeep_1) & \Discard_2^q \le x\\
          \end{cases}   $
          \ElsIf{$\mathbf{Q}_{keep}  \wedge \mathbf{Q}_{discard} \wedge \lnot \mathbf{Q}_{distribute} $}\Comment{Partitioning Distribution}
          \State  
          $ pDis(x) \gets \begin{cases}
           \dstMin & x \le \Discard_1^q \\
           \Scale \; x  + \dstMin  & \Discard_1^q \le x \le \Discard_2^q  \\
           \Discard_2 - \Discard_1 + \dstMin  & \Discard_2^q \le x\\
           \end{cases}$
          \algstore{bkbreak}
\end{algorithmic}
  \caption{An algorithm which returns a channel appropriate distribution function}
\end{algorithm}
\addtocounter{algorithm}{-1}
\begin{algorithm}[h]
\caption{Part 2}
\begin{algorithmic}[1]
\algrestore{bkbreak}
          \ElsIf{$\mathbf{Q}_{keep}  \wedge \lnot \mathbf{Q}_{discard} \wedge \mathbf{Q}_{distribute} $}\Comment{Little Loss Distribution}
          \State $
           pDis(x) \gets \begin{cases}
                    \text{dis}(\Scale x) & \srcMin < x < \eKeep_1^q \\
                    \Scale x - \eKeep_1 + \text{dis}(\eKeep_1) & \eKeep_1^q \le x \le \eKeep_2^q  \\
                    \text{dis}(\Scale x) + \eKeep_2 - \eKeep_1 - \text{dis}(\eKeep_2) + \text{dis}(\eKeep_1)  & \eKeep_2^q < x \\
                    \end{cases}   $
          \ElsIf{$\mathbf{Q}_{keep}  \wedge \lnot \mathbf{Q}_{discard} \wedge \lnot \mathbf{Q}_{distribute} $}\Comment{Linear Distribution}
          \State   
          $  pDis(x) \gets \Scale \; x + \dstMin $
          \ElsIf{$\lnot \mathbf{Q}_{keep}  \wedge \mathbf{Q}_{discard} \wedge \mathbf{Q}_{distribute} $}\Comment{Truncated Erf Distribution}
         \State  
         $ pDis(x) \gets \begin{cases}
          \dstMin & x \le \Discard_1^q \\
          \text{dis}(\Scale x) & \Discard_1^q < x < \Discard_2^q \\
          \dstMax & \Discard_2^q \le x  \\
          \end{cases} $
          \ElsIf{$\lnot\mathbf{Q}_{keep}  \wedge \mathbf{Q}_{discard} \wedge \lnot \mathbf{Q}_{distribute} $}\Comment{Step Distribution!}
         \State   
         $  pDis(x) \gets \begin{cases}
           \dstMin & x \le \frac{\Discard_1^q + \Discard_2^q}{2} \\
           1 + \dstMin  &  \frac{\Discard_1^q + \Discard_2^q}{2} < x\\
           \end{cases} $
            \Else \Comment{$\lnot \mathbf{Q}_{keep}  \wedge \lnot \mathbf{Q}_{discard} \wedge \lnot \mathbf{Q}_{distribute} $}
            \State Error; \Comment{The tolerances or something else must be wrong!}
            \EndIf
            \State \textbf{Return} {$pDis(x)$}
\end{algorithmic}
\end{algorithm}

\subsection{Conclusion}
The matrix $\qRs$ achieves its stated aims of being of integer type and --- when acting upon vectors of the source type --- producing results which fit into a data type of twice the bit depth, but no more. For common source types, the suggested quantized value of $\theta$ will likely be within 1 degree of the requested value, and so there are no unacceptable restrictions on the color-space. And the re-distribution from the working type to the destination type is performed efficiently with the optimization decisions taken by the code itself. The algorithm thus described therefore only requires the color statistics for the object of interest and the orientation of the color-space to be provided by the user, along with optional tolerances variously described above.

During the development of this algorithm, it became apparent with certain coincidences that the same formulations of the rotation would be happened upon in pursuit of different goals. Most notably, the matrix $\fRe$ --- as well as satisfying the optimization goals --- also is the smallest representation which provides a truly lossless rotation. This may be surprising because the matrix $\R$ theoretically provides sufficient space for all the information to be retained. However, there are unavoidable discretization errors which make some values inside the rotated space inaccessible and others $2\rightarrow 1$ from the RGB space to the LCaCb space. So, to be clear, $\fRe$ is the smallest representation which has no $2\rightarrow 1$ loss of information, but has inaccessible values, whereas LCaCb is the most compact representation which has, at worst, $2\rightarrow 1$ errors. 

It should be noted that neither the inaccessible value problem or the $2\rightarrow 1$ loss of information is unique to the factored or discretized representation and is as much of a problem even in a floating-point representation of the rotation. The common implementation is to take a source integer, turn it into a floating-point number, perform the conversion in floating points, then turn it back into an integer; this is the case in OpenCV and other such computer vision libraries. These implementations also suffer from the same problem. Hereafter, the problem of inaccessible values and $2\rightarrow 1$ allocation values due to the discretization will be referred to as "the speckling problem". 


